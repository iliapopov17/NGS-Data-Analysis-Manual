"""
The pipeline for align bacteria samples to reference genome, call and anotate variations

=== Utilities ===
To prepare all utilities one need to do the following:
* Install miniconda from https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
* Configure conda channels
  conda config --add channels defaults && conda config --add channels bioconda && conda config --add channels conda-forge
* Install utilities
  conda create --name bioinf_varcall && conda activate bioinf_varcall
  conda install snakemake-minimal fastqc trimmomatic bwa samtools tabix gatk4 snpeff entrez-direct sra-tools
"""

# File containing names of reference gemone and samples
configfile: "config.yaml"

# Parameters form config file
MAXTHREADS=config["maxthreads"]
REFERENCE_ID=config["reference_ncbi_id"]
REFERENCE=config["reference"]
SAMPLES=config["samples"]

# Defualt rule to analyse all samples
rule all:
    input:
        expand('{reference}.{sample}.higheffect.vcf', sample=SAMPLES, reference=REFERENCE)

rule fetch_reference_fasta:
    # Download reference file from NCBI in FASTA format
    output: 
        REFERENCE+".fa"
    params:  ref_id=REFERENCE_ID
    conda:  "varcall.yaml"
    shell:  "efetch -db nuccore -id {params.ref_id} -format fasta > {output}"

rule fetch_reference_gb:
    # Download reference file from NCBI in GB format
    output: 
        REFERENCE+".gb"
    params:  ref_id=REFERENCE_ID
    conda:  "varcall.yaml"
    shell:  "efetch -db nuccore -id {params.ref_id} -format gb > {output}"


rule fetch_sample:
    # Download sample FASTQ files from SRA via sra-tools
    output: 
        "{sample}_1.fastq.gz",
        "{sample}_2.fastq.gz",
    params: sra_id="{sample}"
    conda:  "varcall.yaml"
    shell:  "fastq-dump -v --split-3 --gzip {params.sra_id}"

rule reference_index_bwa:
    # Prepare BWA index for gzipped fasta
    input:  "{reference}.fa"
    output: multiext("{reference}.fa", ".amb", ".ann", ".bwt",".pac",".sa")
    conda:  "varcall.yaml"
    shell:  "bwa index {input}"

rule ref_index_fai:
    # Make fai index for fasta reference (required by GATK and some other utilities)
    input:  "{reference}.fa"
    output: "{reference}.fa.fai"
    conda:  "varcall.yaml"
    shell:  "samtools faidx {input}"

rule ref_index_dict:
    # Make dict index for fasta reference (required by GATK) 
    input:  "{reference}.fa"
    output: "{reference}.dict"
    conda:  "varcall.yaml"
    shell:  "samtools dict {input} > {output}"

rule sample_trimmomatic:
    # Quality trim for sample fastq files
    input:
        "{sample}_1.fastq.gz",
        "{sample}_2.fastq.gz"
    output:
        "{sample}_R1.trim.paired.fastq.gz",
        "{sample}_R1.trim.unpaired.fastq.gz",
        "{sample}_R2.trim.paired.fastq.gz",
        "{sample}_R2.trim.unpaired.fastq.gz"
    log: "logs/{sample}.reads_trim.log"
    threads: MAXTHREADS
    params: trimrule="LEADING:22 TRAILING:22 SLIDINGWINDOW:6:22 MINLEN:32"
    conda:  "varcall.yaml"
    shell:  "trimmomatic PE -threads {threads} {input} {output} {params.trimrule} 2> {log}"

rule bwa_align:
    # Aligh reads to reference
    input:
        rules.reference_index_bwa.output,
        ref="{reference}.fa",
        r1="{sample}_R1.trim.paired.fastq.gz",
        r2="{sample}_R2.trim.paired.fastq.gz"
    output: "{reference}.{sample}.unsorted.bam"
    log:    "logs/{reference}.{sample}.bwa_align.log"
    threads: MAXTHREADS
    resources:
        mem_gb=4
    params: readgroup=r"@RG\tID:1\tPL:illumina\tPU:barcode1\tSM:{sample}\tLB:Library1\tCN:BioschoolVarCall"
    conda:  "varcall.yaml"
    shell:  r'''bwa mem -t {threads} -R '{params.readgroup}' {input.ref} {input.r1} {input.r2} 2> {log} | samtools view -b > {output}'''

rule bam_sort:
    # Sort BAM file
    input:  "{sample}.unsorted.bam"
    output: "{sample}.sorted.bam"
    log:    "logs/{sample}.bam_sort.log"
    threads: MAXTHREADS
    conda:  "varcall.yaml"
    shell:  "samtools sort --threads {threads} {input} > {output} 2> {log}"

rule bam_index:
    # Make BAI index for BAM file
    input:  "{sample}.bam"
    output: "{sample}.bam.bai"
    conda:  "varcall.yaml"
    shell:  "samtools index {input}"

rule realign_indels:
    # Realigh reads around indels to achieve better indels calling
    input:
        ref="{reference}.fa",
        bam="{reference}.{sample}.sorted.bam",
        bai="{reference}.{sample}.sorted.bam.bai"
    output: "{reference}.{sample}.final.bam",
    benchmark: "{reference}.{sample}.abra2_realign.benchmark.txt"
    log:    "logs/{reference}.{sample}.abra2_realign.log"
    threads: MAXTHREADS
    conda:  "varcall.yaml"
    shell:  """JAVA_TOOL_OPTIONS="-Xmx8G" abra2 --threads {threads} --mad 100 --mbq 24 --ref {input.ref} --in {input.bam} --out {output} 2> {log}"""
    
rule call_variants_bcftools:
    # Run variant caller on final BAM file - bcftools
    input:
        ref="{reference}.fa",
        reffai="{reference}.fa.fai",
        bam="{reference}.{sample}.final.bam",
        bai="{reference}.{sample}.final.bam.bai"
    output: "{reference}.{sample}.called.bcftools.vcf",
    benchmark: "{reference}.{sample}.call_variants.bcftools.benchmark.txt"
    log:    "logs/{reference}.{sample}.call_variants.bcftools.log"
    conda:  "varcall.yaml"
    shell:  "bcftools mpileup -Ou --max-depth 5000 -f {input.ref} {input.bam} | bcftools call -mv --ploidy 1 -Ov -o {output}"

    
rule call_variants_gatk:
    # Run variant caller on final BAM file
    # Not used in this pipeline now. To use it instead of bcftools, just change the required file name in vcf_annotate_variants
    input:
        ref="{reference}.fa",
        reffai="{reference}.fa.fai",
        refdict="{reference}.dict",
        bam="{reference}.{sample}.sorted.bam",
        bai="{reference}.{sample}.sorted.bam.bai"
    output: "{reference}.{sample}.called.gatk.vcf",
    log:    "logs/{reference}.{sample}.call_variants.gatk4.log"
    conda:  "varcall.yaml"
    shell:  "gatk HaplotypeCaller --reference {input.ref} --input {input.bam} --output {output} 2> {log}"

rule vcf_index:
    # Make tabix index for VCF file
    input:  "{sample}.vcf.gz"
    output: "{sample}.vcf.gz.tbi"
    conda:  "varcall.yaml"
    shell:  "tabix {input} {output}"

rule make_snpeff_database:
    # Create snpeff database from GeneBank file
    input:  "{reference}.gb"
    output: 
        dir=directory("data/{reference}")
    conda:  "varcall.yaml"
    params: 
        genome = "{reference}",
        dir="data/{reference}",
        snpeff_config = """{reference}.genome : {reference}
        {reference}.chromosomes : {reference}.gb
        {reference}.codonTable : Standard"""
    log:    "logs/{reference}.snpeff_db.log"
    conda:  "varcall.yaml"
    shell:"""
        echo "{params.snpeff_config}" > snpEff.config
        mkdir -p {output}
        cp {input} {params.dir}/genes.gbk
        snpEff build -c snpEff.config -genbank {params.genome} 2> {log}
        """

rule vcf_annotate_variants:
    # Annotate VCF file
    input:  
        database=rules.make_snpeff_database.output,
        vcf="{reference}.{sample}.called.bcftools.vcf"
    output: 
        vcf="{reference}.{sample}.annotated.vcf",
        genes="{reference}.{sample}.snpEff_genes.txt",
        summary="{reference}.{sample}.snpEff_summary.html",
    log:    "logs/{reference}.{sample}.annotate_variants.log"
    threads: MAXTHREADS
    params: genome="{reference}"
    conda:  "varcall.yaml"
    shell:  """snpEff ann -v {params.genome}  {input.vcf} > {output.vcf} 2> {log}
               mv snpEff_genes.txt {output.genes}
               mv snpEff_summary.html {output.summary}"""

rule vcf_filter_effect:
    # Select only high and moderate impact variations
    input:  "{reference}.{sample}.annotated.vcf"
    output: "{reference}.{sample}.higheffect.vcf",
    conda:  "varcall.yaml"
    shell:  """SnpSift filter "(ANN[*].IMPACT has 'HIGH') | (ANN[*].IMPACT has 'MODERATE')" {input} > {output}"""
