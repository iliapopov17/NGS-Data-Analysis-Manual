---
title: "16S analysis with DADA2"
author: "Ilia Popov"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
#install.packages("rmarkdown", repos = "https://cran.revolutionanalytics.com")
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading the necessary packages and data

First, let's download the necessary packages.

```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
    
#BiocManager::install("dada2")
library(dada2)
```

```{r}
main_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(main_dir)
```

The data we will be working with are the same as those used in the mothur MiSeq SOP. The data can be downloaded here: https://mothur.s3.us-east-2.amazonaws.com/wiki/miseqsopdata.zip 

```{r}
url <- "https://mothur.s3.us-east-2.amazonaws.com/wiki/miseqsopdata.zip"

zipF<- "miseqsopdata.zip"

download.file(url, zipF)

outDir<-"miseqsopdata"

unzip(zipF,exdir=outDir)

if (file.exists(zipF)) {
  file.remove(zipF)
}
```

These are the results of sequencing 2x250 Illumina Miseq amplicons of the V4 region of the 16S rRNA gene from gut samples collected from mice after weaning. For now, these are just paired reads for us.

Here we look at the contents of the folder and save the filenames of the forward and reverse reads as separate vectors (`forward.raw` and `reverse.raw`), distinguishing them by suffix. The last line creates a list of samples, removing all characters except the sample number.

```{r}
path <- 'miseqsopdata/MiSeq_SOP'
list.files(path)
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

Now let's check the quality of the data. This function creates graphs similar to `FastQC` or `multiQC` graphs.

```{r}
plotQualityProfile(fnFs[1:2])
```

We can do the same for reverse reads.

```{r}
plotQualityProfile(fnRs[1:2])
```

Now we can filter by quality and trim reads based on the resulting graphs:

```{r}
filt_path <- file.path(path, "filtered")
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE

out
```

## Building an error model 

Evaluating the error model for the `DADA2` algorithm using direct reads.

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

Same model for reverse reads

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```

Error graph for all possible base transitions

```{r}
plotErrors(errF, nominalQ=TRUE)
```

## Dereplication and "denoising"

To speed up the calculations, we can remove identical sequences, taking into account their number in the subsequent analysis.
For the obtained objects, we keep the same sample names.

```{r echo=T, results='hide', message=F, warning=FALSE}
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```

Now we run the main algorithm to determine ASV for forward and reverse reads.

```{r echo=T, results='hide', message=F, warning=FALSE}
dadaFs <- dada(derepFs, err=errF, pool=T, multithread=TRUE) 
dadaRs <- dada(derepRs, err=errR, pool=T, multithread=TRUE)
```

## Merging reads, summary statistics

Now we can "glue" the forward and reverse reads for each pair into one sequence.

```{r echo=T, results='hide', message=F, warning=FALSE}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)

seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

## Removal of chimeras

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```

```{r}
dim(seqtab.nochim)
sum(seqtab.nochim)/sum(seqtab)
```

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

## Taxonomy identification

To determine the taxonomic position of the found sequences, we first need to download the classifier.
https://zenodo.org/record/1172783/files/silva_nr_v132_train_set.fa.gz

```{r}
url <- "https://zenodo.org/record/1172783/files/silva_nr_v132_train_set.fa.gz"

classifier_1 <- "silva_nr_v132_train_set.fa.gz"

download.file(url, classifier_1)
```

A separate classifier will be required to identify species
https://zenodo.org/record/1172783/files/silva_species_assignment_v132.fa.gz?download=1

```{r}
url <- "https://zenodo.org/record/1172783/files/silva_species_assignment_v132.fa.gz?download=1"

classifier_2 <- "silva_species_assignment_v132.fa.gz"

download.file(url, classifier_2)
```

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "silva_nr_v132_train_set.fa.gz", multithread=TRUE)
```

Adding Species Information

```{r}
taxa <- addSpecies(taxa, "silva_species_assignment_v132.fa.gz", verbose=TRUE, allowMultiple=T)
```

```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

## Additional: Translation into `Phyloseq` format

First, download the necessary packages

```{r}
BiocManager::install("phyloseq")
```

```{r}

library(phyloseq); packageVersion("phyloseq")
library(Biostrings); packageVersion("Biostrings")
library(ggplot2); packageVersion("ggplot2")
theme_set(theme_bw())

```

Then we add metadata

```{r}
samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, "D"), `[`, 1)
gender <- substr(subject,1,1)
subject <- substr(subject,2,999)
day <- as.integer(sapply(strsplit(samples.out, "D"), `[`, 2))
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)
samdf$When <- "Early"
samdf$When[samdf$Day>100] <- "Late"
rownames(samdf) <- samples.out
```

And finally, we create a `phyloseq` object

```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample
```

With it, you can already do any subsequent analysis. For example, calculate alpha diversity

```{r}
plot_richness(ps, x="Day", measures=c("Shannon", "Simpson"), color="When")
```

```{r}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Day", fill="Family") + facet_wrap(~When, scales="free_x")
```
## References

The following packages must be installed to work with the dataset:

```{r}
knitr::write_bib(c("BiocManager", "dada2", "phyloseq", "Biostrings",
                   "ggplot2"), file = "packages.bib")
```